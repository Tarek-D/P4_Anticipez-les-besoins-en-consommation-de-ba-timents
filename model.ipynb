{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compréhension du problème :\n",
    "On travaille sur un problème de régression, car on essaye de prédire une valeur numérique continue 'SiteEnergyUse(kBtu)', 'TotalGHGEmissions' à partir de caractéristiques de bâtiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les modèles testés seront les suivants : \n",
    "\n",
    "## Linear Regression (Régression linéaire):\n",
    "La régression linéaire est un modèle de régression simple qui tente de modéliser la relation linéaire entre les caractéristiques (variables prédictives) et la variable cible.\n",
    "L'objectif est de trouver une ligne droite (ou un hyperplan en plusieurs dimensions) qui minimise l'erreur quadratique moyenne entre les prédictions du modèle et les valeurs réelles de la variable cible.\n",
    "C'est un modèle simple et facile à interpréter, mais il suppose que la relation entre les caractéristiques et la cible est linéaire, ce qui peut ne pas être vrai dans tous les cas.\n",
    "\n",
    "## ElasticNet:\n",
    "ElasticNet est une extension de la régression linéaire qui combine à la fois la régression L1 (Lasso) et la régression L2 (Ridge).\n",
    "Il est utilisé pour gérer le problème de la multicollinéarité (lorsque les caractéristiques sont fortement corrélées) et pour effectuer la sélection automatique des caractéristiques en réduisant les coefficients de certaines caractéristiques à zéro.\n",
    "Les paramètres alpha et l1_ratio permettent de contrôler le mélange entre L1 et L2.\n",
    "\n",
    "## Random Forest Regressor (Régresseur à forêts aléatoires):\n",
    "Les forêts aléatoires sont des modèles d'ensemble basés sur des arbres de décision.\n",
    "Dans le cas du régresseur à forêts aléatoires, de nombreux arbres de décision sont construits lors de l'apprentissage et les prédictions finales sont la moyenne des prédictions de chaque arbre.\n",
    "Ils sont très flexibles et peuvent modéliser des relations complexes entre les caractéristiques et la variable cible. Ils sont également robustes face aux données bruyantes et aux valeurs aberrantes.\n",
    "\n",
    "## Gradient Boosting Regressor (Régresseur par Gradient Boosting):\n",
    "Le régresseur par gradient boosting est un autre modèle d'ensemble qui construit un modèle prédictif en ajoutant séquentiellement des arbres de décision faibles.\n",
    "À chaque étape, le modèle tente de corriger les erreurs du modèle précédent en ajustant les poids des observations mal prédites.\n",
    "Cela conduit généralement à un modèle très puissant, capable de modéliser des relations complexes. Cependant, il est plus susceptible de sur-ajuster si les hyperparamètres ne sont pas correctement réglés.\n",
    "\n",
    "## Support Vector Regressor (Régresseur à vecteurs de support):\n",
    "Le régresseur à vecteurs de support est utilisé pour la régression. Il est basé sur le même principe que la classification SVM, mais il vise à minimiser les erreurs de prédiction pour les données de régression.\n",
    "Il tente de trouver un hyperplan (ou une surface hyperplane en plusieurs dimensions) qui maximise la marge entre les points de données et la prédiction du modèle.\n",
    "Il est efficace pour les données de faible dimension, mais peut être moins approprié pour les ensembles de données de grande dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_saved.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement de la liste des targets et features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load('features.npy')\n",
    "targets = np.load('targets.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'une liste de caractéristiques continues et catégorielles pour différencier quelles caractéristiques nécessitent un traitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caractéristiques continues : ['NumberofBuildings', 'PropertyGFATotal', 'PropertyGFABuilding(s)', 'BuildingAge', 'LargestPropertyUseTypeGFA', 'Electricity(kWh)', 'Electricity(kBtu)']\n",
      "Caractéristiques catégorielles : ['PrimaryPropertyType']\n"
     ]
    }
   ],
   "source": [
    "# Initialisation des listes vides pour les caractéristiques continues et catégorielles\n",
    "features_continuous = []\n",
    "features_categorical = []\n",
    "\n",
    "# Boucle à travers les caractéristiques et identification de leur type de données\n",
    "for feature in features:\n",
    "    dtype = data[feature].dtype\n",
    "    if np.issubdtype(dtype, np.number):  # Vérifiez si c'est un type de données numérique\n",
    "        features_continuous.append(feature)\n",
    "    else:\n",
    "        features_categorical.append(feature)\n",
    "\n",
    "# Affichez les caractéristiques continues et catégorielles\n",
    "print(\"Caractéristiques continues :\", features_continuous)\n",
    "print(\"Caractéristiques catégorielles :\", features_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SiteEnergyUse(kBtu)' 'TotalGHGEmissions']\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caractéristiques continues : ['NumberofBuildings', 'PropertyGFATotal', 'PropertyGFABuilding(s)', 'BuildingAge', 'LargestPropertyUseTypeGFA', 'Electricity(kWh)', 'Electricity(kBtu)']\n",
      "Caractéristiques catégorielles : ['PrimaryPropertyType']\n"
     ]
    }
   ],
   "source": [
    "print(\"Caractéristiques continues :\", features_continuous)\n",
    "print(\"Caractéristiques catégorielles :\", features_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline complet avec le préprocesseur et le modèles d'apprentissages supervisés pour target 'SiteEnergyUse(kBtu)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearRegression\n",
      "Mean Squared Error: 150691.68405575003\n",
      "R-squared: 0.7623781698027438\n",
      "\n",
      "Model: ElasticNet\n",
      "Mean Squared Error: 265730.4350402563\n",
      "R-squared: 0.5809765302641503\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Mean Squared Error: 91242.15376812387\n",
      "R-squared: 0.8561226008895095\n",
      "\n",
      "Model: GradientBoostingRegressor\n",
      "Mean Squared Error: 127046.40793112261\n",
      "R-squared: 0.7996637959038814\n",
      "\n",
      "Model: SVR\n",
      "Mean Squared Error: 641167.8570561055\n",
      "R-squared: -0.011041057852661407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Définissez vos caractéristiques X et votre variable cible y\n",
    "X = data[features]\n",
    "y = data['SiteEnergyUse(kBtu)']\n",
    "\n",
    "# Divisez les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Liste des colonnes numériques\n",
    "numerical_cols = ['NumberofBuildings', 'PropertyGFATotal', 'PropertyGFABuilding(s)', 'BuildingAge', 'LargestPropertyUseTypeGFA', 'Electricity(kWh)', 'Electricity(kBtu)']\n",
    "\n",
    "# Liste des colonnes catégorielles (à encoder en one-hot)\n",
    "categorical_cols = ['PrimaryPropertyType']\n",
    "\n",
    "# Créez un préprocesseur pour les caractéristiques numériques\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Préprocesseur pour les colonnes catégorielles (encodage en one-hot)\n",
    "categorical_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "\n",
    "# Créez une fonction pour entraîner et évaluer un modèle\n",
    "def train_evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Créer un pipeline avec le préprocesseur et le modèle\n",
    "    # Définition du ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Entraîne le modèle via le pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Fait des prédictions sur les données de test\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Évalue la performance du modèle\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "    return mse, r_squared\n",
    "\n",
    "# Créer une liste d'algorithmes à tester\n",
    "models_to_test = [\n",
    "    LinearRegression(),\n",
    "    ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    SVR()\n",
    "]\n",
    "\n",
    "# Boucle à travers les modèles, entraînements et évaluations\n",
    "for model in models_to_test:\n",
    "    mse, r_squared = train_evaluate_model(model, X_train, y_train, X_test, y_test)\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    print(\"R-squared:\", r_squared)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
