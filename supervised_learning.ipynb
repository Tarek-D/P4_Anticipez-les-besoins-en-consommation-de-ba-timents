{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compréhension du problème :\n",
    "On travaille sur un problème de régression a priori, car on essaye de prédire une valeur numérique continue 'SiteEnergyUse(kBtu)', 'TotalGHGEmissions' à partir de caractéristiques de bâtiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les modèles testés seront les suivants : \n",
    "\n",
    "\n",
    "## Linear Regression (Régression linéaire):\n",
    "La régression linéaire est un modèle de régression simple qui tente de modéliser la relation linéaire entre les caractéristiques (variables prédictives) et la variable cible.\n",
    "L'objectif est de trouver une ligne droite (ou un hyperplan en plusieurs dimensions) qui minimise l'erreur quadratique moyenne entre les prédictions du modèle et les valeurs réelles de la variable cible.\n",
    "C'est un modèle simple et facile à interpréter, mais il suppose que la relation entre les caractéristiques et la cible est linéaire, ce qui peut ne pas être vrai dans tous les cas.\n",
    "\n",
    "## ElasticNet:\n",
    "ElasticNet est une extension de la régression linéaire qui combine à la fois la régression L1 (Lasso) et la régression L2 (Ridge).\n",
    "Il est utilisé pour gérer le problème de la multicollinéarité (lorsque les caractéristiques sont fortement corrélées) et pour effectuer la sélection automatique des caractéristiques en réduisant les coefficients de certaines caractéristiques à zéro.\n",
    "Les paramètres alpha et l1_ratio permettent de contrôler le mélange entre L1 et L2.\n",
    "\n",
    "\n",
    "## Random Forest Regressor (Régresseur à forêts aléatoires):\n",
    "Les forêts aléatoires sont des modèles d'ensemble basés sur des arbres de décision.\n",
    "Dans le cas du régresseur à forêts aléatoires, de nombreux arbres de décision sont construits lors de l'apprentissage et les prédictions finales sont la moyenne des prédictions de chaque arbre.\n",
    "Ils sont très flexibles et peuvent modéliser des relations complexes entre les caractéristiques et la variable cible. Ils sont également robustes face aux données bruyantes et aux valeurs aberrantes.\n",
    "\n",
    "## Gradient Boosting Regressor (Régresseur par Gradient Boosting):\n",
    "Le régresseur par gradient boosting est un autre modèle d'ensemble qui construit un modèle prédictif en ajoutant séquentiellement des arbres de décision faibles.\n",
    "À chaque étape, le modèle tente de corriger les erreurs du modèle précédent en ajustant les poids des observations mal prédites.\n",
    "Cela conduit généralement à un modèle très puissant, capable de modéliser des relations complexes. Cependant, il est plus susceptible de sur-ajuster si les hyperparamètres ne sont pas correctement réglés.\n",
    "\n",
    "## Support Vector Regressor (Régresseur à vecteurs de support):\n",
    "Le régresseur à vecteurs de support est utilisé pour la régression. Il est basé sur le même principe que la classification SVM, mais il vise à minimiser les erreurs de prédiction pour les données de régression.\n",
    "Il tente de trouver un hyperplan (ou une surface hyperplane en plusieurs dimensions) qui maximise la marge entre les points de données et la prédiction du modèle.\n",
    "Il est efficace pour les données de faible dimension, mais peut être moins approprié pour les ensembles de données de grande dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle d'apprentissage automatique (comme une régression linéaire) a quelques paramètres ajustables pour qu'il fonctionne mieux. \n",
    "Par exemple, pour la régression linéaire, on peut ajuster la valeur de régularisation.\n",
    "\n",
    "On ne connait pas la meileur valeure régularisation mais on pourrait tester différentes valeurs (comme 0.1, 0.01, 0.001, etc.) et voir laquelle donne les meilleurs résultats. Cela peut prendre beaucoup de temps et d'efforts.\n",
    "\n",
    "GridSearchCV permet de donner liste de valeurs possibles pour chaque paramètre et va tester toutes les combinaisons possibles de ces valeurs pour les paramètres, en ajustant le modèle et évaluant ses performances sur vos données d'entraînement. Il enregistre les performances pour chaque combinaison.\n",
    "\n",
    "GridSearchCV nous donne la meilleure combinaison de paramètres qui donne les meilleures performances sur nos données d'entraînement. C'est comme demander à un ordinateur de trouver la meilleure configuration pour notre modèle, au lieu de le faire manuellement.\n",
    "\n",
    "Cela permet d'optimiser le modèle et d'obtenir de meilleurs résultats sans avoir à essayer chaque combinaison possible nous-même.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparamètres \n",
    "\n",
    "Aucun hyperparamètre à régler : LinearRegression est un modèle de régression linéaire simple qui ne possède pas d'hyperparamètres spécifiques à régler lors de la recherche par grille. Il s'agit d'un modèle linéaire de base qui ajuste une ligne droite aux données.\n",
    "\n",
    "### ElasticNet :\n",
    "* model__alpha : Le paramètre d'ajustement alpha contrôle la régularisation du modèle. Il s'agit d'un coefficient qui pondère la pénalité L1 (lasso) et la pénalité L2 (ridge). Les valeurs plus élevées d'alpha augmentent la régularisation. Nous essayons trois valeurs différentes : 0.01, 0.1 et 1.0.\n",
    "* model__l1_ratio : Le rapport l1_ratio contrôle le mélange entre la régularisation L1 et L2. Une valeur de 1 signifie une régularisation L1 pure (lasso), 0 signifie une régularisation L2 pure (ridge), et une valeur entre les deux effectue un mélange des deux. Nous essayons trois valeurs différentes : 0.1, 0.5 et 0.9.\n",
    "* model__max_iter : Le nombre maximum d'itérations pour la convergence de l'algorithme d'optimisation. Nous essayons deux valeurs : 1000 et 2000.\n",
    "\n",
    "### RandomForestRegressor :\n",
    "* model__n_estimators : Le nombre d'arbres de décision dans la forêt aléatoire. Plus il y a d'arbres, mieux c'est, mais cela peut augmenter le temps de calcul. Nous essayons trois valeurs différentes : 50, 100 et 200.\n",
    "* model__max_depth : La profondeur maximale de chaque arbre de décision. Une profondeur plus grande peut conduire à un surajustement. Nous essayons quatre valeurs différentes : None (pas de limite de profondeur), 10, 20 et 30.\n",
    "\n",
    "### GradientBoostingRegressor :\n",
    "* model__n_estimators : Le nombre d'itérations pour ajuster les arbres de décision. Plus il y en a, plus le modèle est complexe. Nous essayons trois valeurs différentes : 50, 100 et 200.\n",
    "* model__max_depth : La profondeur maximale de chaque arbre de décision dans le gradient boosting. Une profondeur plus grande peut conduire à un surajustement. Nous essayons trois valeurs différentes : 3, 4 et 5.\n",
    "\n",
    "### SVR (Support Vector Regressor) :\n",
    "* model__C : Le paramètre de régularisation qui contrôle la tolérance aux erreurs d'entraînement. Des valeurs plus élevées de C permettent une meilleure adéquation aux données d'entraînement, mais peuvent entraîner un surajustement. Nous essayons trois valeurs différentes : 0.1, 1 et 10.\n",
    "* model__kernel : Le noyau utilisé dans le modèle SVR. Nous essayons deux noyaux différents : \"linear\" (linéaire) et \"rbf\" (radial basis function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from  sklearn.model_selection import learning_curve \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_saved.csv')\n",
    "data_energyscore = pd.read_csv('data_energyscore.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1662, 43)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement de la liste des targets et features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load('features.npy')\n",
    "targets = np.load('targets.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'une liste de caractéristiques continues et catégorielles pour différencier quelles caractéristiques nécessitent un traitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caractéristiques continues : ['ConsommeGaz', 'NumberofBuildings', 'PropertyGFATotal', 'PropertyGFABuilding(s)', 'BuildingAge', 'LargestPropertyUseTypeGFA', 'Electricity(kWh)', 'Electricity(kBtu)']\n",
      "Caractéristiques catégorielles : ['Neighborhood', 'LargestPropertyUseType', 'PrimaryPropertyType']\n"
     ]
    }
   ],
   "source": [
    "# Initialisation des listes vides pour les caractéristiques continues et catégorielles\n",
    "features_continuous = []\n",
    "features_categorical = []\n",
    "\n",
    "# Boucle à travers les caractéristiques et identification de leur type de données\n",
    "for feature in features:\n",
    "    dtype = data[feature].dtype\n",
    "    if np.issubdtype(dtype, np.number):  # Vérifiez si c'est un type de données numérique\n",
    "        features_continuous.append(feature)\n",
    "    else:\n",
    "        features_categorical.append(feature)\n",
    "\n",
    "# Affichez les caractéristiques continues et catégorielles\n",
    "print(\"Caractéristiques continues :\", features_continuous)\n",
    "print(\"Caractéristiques catégorielles :\", features_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SiteEnergyUse(kBtu)' 'TotalGHGEmissions']\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caractéristiques continues : ['ConsommeGaz', 'NumberofBuildings', 'PropertyGFATotal', 'PropertyGFABuilding(s)', 'BuildingAge', 'LargestPropertyUseTypeGFA', 'Electricity(kWh)', 'Electricity(kBtu)']\n",
      "Caractéristiques catégorielles : ['Neighborhood', 'LargestPropertyUseType', 'PrimaryPropertyType']\n"
     ]
    }
   ],
   "source": [
    "print(\"Caractéristiques continues :\", features_continuous)\n",
    "print(\"Caractéristiques catégorielles :\", features_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline complet avec le préprocesseur et le modèles d'apprentissages supervisés pour target 'SiteEnergyUse(kBtu)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearRegression()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " R² de chaque fold: [-2.74067732e+13]\n",
      " R² data entrainement : -19885692862916.62\n",
      " R² data test: -276713908358978.97\n",
      "Mean Absolute Error: 3110736.294440306\n",
      "Coefficients:\n",
      "[ 1.07453551e+06  1.75533389e+06  3.13624491e+05  1.47144615e+07\n",
      "  6.24295216e+05  5.28476285e+07  3.84249559e+06  4.84123201e+05\n",
      "  8.15670694e+06 -2.78757938e+06 -1.92473625e+05  6.45366934e+05\n",
      "  5.34610791e+05  7.83909370e+03  9.85486646e+05 -5.31445643e+04\n",
      "  8.90396969e+05  2.94358060e+06  2.31702402e+05 -1.53934083e+05\n",
      "  4.54971911e+06  2.62335578e+05  2.51043772e+06  2.92289344e+06\n",
      "  1.25744078e+05  2.86349453e+05]\n",
      "Model: LinearRegression\n",
      "Best Hyperparameters: {}\n",
      "Mean Squared Error: 276713908358978.97\n",
      "R²: 0.9130994105159829\n",
      "Training Time 3.375018835067749\n",
      "\n",
      "************************************************\n",
      "************************************************\n",
      "Model: ElasticNet(alpha=0.5)\n",
      " R² de chaque fold: [-2.86332462e+13 -2.86332462e+13 -2.80423628e+13 -2.80423628e+13\n",
      " -2.75163199e+13 -2.75163199e+13 -3.66602780e+13 -3.66602780e+13\n",
      " -3.38072258e+13 -3.38072258e+13 -2.87844829e+13 -2.87844829e+13\n",
      " -4.31859061e+13 -4.31859061e+13 -4.19865667e+13 -4.19865667e+13\n",
      " -3.71615362e+13 -3.71615362e+13]\n",
      " R² data entrainement : -19893050741871.19\n",
      " R² data test: -277074912510662.9\n",
      "Mean Absolute Error: 3120802.993008828\n",
      "Coefficients:\n",
      "[ 1.08982051e+06  1.75494840e+06  3.14966588e+05  1.47483611e+07\n",
      "  6.22216820e+05  5.15380910e+07  3.59137875e+06  2.53434980e+05\n",
      "  7.77574311e+06 -3.05251080e+06 -3.99750085e+05  3.97131613e+05\n",
      "  2.91444416e+05 -2.04145310e+05  7.40344228e+05 -2.84522062e+05\n",
      "  6.53316228e+05  2.67404636e+06 -2.60267042e+03 -3.80210952e+05\n",
      "  4.27620955e+06  2.95814361e+04  2.26070816e+06  2.61273478e+06\n",
      " -1.04102939e+05  5.91961890e+04]\n",
      "Model: ElasticNet\n",
      "Best Hyperparameters: {'model__alpha': 0.001, 'model__l1_ratio': 0.9, 'model__max_iter': 1000}\n",
      "Mean Squared Error: 277074912510662.9\n",
      "R²: 0.9129860390061315\n",
      "Training Time 2.193249225616455\n",
      "\n",
      "************************************************\n",
      "************************************************\n",
      "Model: RandomForestRegressor()\n",
      " R² de chaque fold: [-2.90058238e+13 -3.01115649e+13 -2.72287962e+13 -2.80497715e+13\n",
      " -2.78462684e+13 -2.83700534e+13 -2.79061754e+13 -2.63030963e+13]\n",
      " R² data entrainement : -3798469865783.7983\n",
      " R² data test: -1354560417203299.2\n",
      "Mean Absolute Error: 4353389.419202144\n",
      "Feature Importance:\n",
      "[1.11806757e-02 1.13985344e-02 1.16119539e-02 9.31915030e-01\n",
      " 7.47308496e-03 1.18060156e-02 3.26559575e-03 7.64922143e-05\n",
      " 8.53322036e-04 2.95086652e-03 3.13457659e-07 3.01756856e-04\n",
      " 7.54636762e-04 4.30518748e-08 1.63531303e-03 1.21592244e-05\n",
      " 2.86498903e-05 3.21870222e-04 1.64979985e-04 1.38469966e-06\n",
      " 1.35659100e-03 1.30013789e-04 3.09124426e-04 2.30737724e-03\n",
      " 1.20576151e-04 2.36387603e-05]\n",
      "Model: RandomForestRegressor\n",
      "Best Hyperparameters: {'model__max_depth': 30, 'model__n_estimators': 100}\n",
      "Mean Squared Error: 1354560417203299.2\n",
      "R²: 0.5746072199812382\n",
      "Training Time 6.977406978607178\n",
      "\n",
      "************************************************\n",
      "************************************************\n",
      "Model: GradientBoostingRegressor()\n",
      " R² de chaque fold: [-2.42790202e+13 -2.43333217e+13 -1.82857491e+13 -1.75844107e+13\n",
      " -1.96395730e+13 -1.97211460e+13]\n",
      " R² data entrainement : -2047312900544.8833\n",
      " R² data test: -1557048798584134.0\n",
      "Mean Absolute Error: 4615633.296073977\n",
      "Model: GradientBoostingRegressor\n",
      "Best Hyperparameters: {'model__max_depth': 4, 'model__n_estimators': 100}\n",
      "Mean Squared Error: 1557048798584134.0\n",
      "R²: 0.5110167781056842\n",
      "Training Time 1.309690237045288\n",
      "\n",
      "************************************************\n",
      "************************************************\n",
      "Model: SVR()\n",
      " R² de chaque fold: [-3.70697528e+14 -3.70700178e+14 -3.70672607e+14 -3.70699681e+14]\n",
      " R² data entrainement : -370665881346794.9\n",
      " R² data test: -3264879362395848.5\n",
      "Mean Absolute Error: 10392414.346072685\n",
      "Model: SVR\n",
      "Best Hyperparameters: {'model__C': 1, 'model__kernel': 'linear'}\n",
      "Mean Squared Error: 3264879362395848.5\n",
      "R²: -0.025318686975189797\n",
      "Training Time 0.3528618812561035\n",
      "\n",
      "************************************************\n",
      "************************************************\n"
     ]
    }
   ],
   "source": [
    "# Caractéristiques X et  variable cible y\n",
    "X = data[features]\n",
    "y = data['SiteEnergyUse(kBtu)']\n",
    "\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=data['PrimaryPropertyType'])\n",
    "\n",
    "# Liste des colonnes numériques \n",
    "numerical_cols = ['NumberofBuildings', 'PropertyGFATotal', 'BuildingAge', 'Electricity(kWh)', 'ConsommeGaz']\n",
    "\n",
    "# Liste des colonnes catégorielles (à encoder en one-hot)\n",
    "categorical_cols = ['PrimaryPropertyType']\n",
    "\n",
    "# Préprocesseur pour les caractéristiques numériques\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Préprocesseur pour les colonnes catégorielles (encodage en one-hot)\n",
    "categorical_transformer = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "\n",
    "# Créer une fonction pour entraîner et évaluer un modèle avec GridSearchCV\n",
    "def train_evaluate_model_with_grid_search(model, param_grid, X_train, y_train, X_test, y_test):\n",
    "    # Créez un pipeline avec le préprocesseur et le modèle\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ])\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    print('Model:', model)\n",
    "    \n",
    "    # Créer l'objet GridSearchCV\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    \n",
    "    # Mesure le temps de calcul\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Entraîne le modèle avec GridSearchCV\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # Donne le R2 de chaque fold \n",
    "    r2_scores = grid_search.cv_results_['mean_test_score']\n",
    "    print(\" R² de chaque fold:\", r2_scores)\n",
    "\n",
    "    # Donne R² entrainement / test\n",
    "    train_r2 = grid_search.score(X_train, y_train)\n",
    "    test_r2 = grid_search.score(X_test, y_test)\n",
    "    print(\" R² data entrainement :\", train_r2)\n",
    "    print(\" R² data test:\", test_r2)\n",
    "    \n",
    "    # Fait des prédictions sur les données de test\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    \n",
    "    # Évalue la performance du modèle\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Calcule la Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    if 'LinearRegression' in model_name:\n",
    "        if hasattr(grid_search.best_estimator_.named_steps['model'], 'coef_'):\n",
    "            print(\"Coefficients:\")\n",
    "            print(grid_search.best_estimator_.named_steps['model'].coef_)\n",
    "\n",
    "    if 'ElasticNet' in model_name:\n",
    "        if hasattr(grid_search.best_estimator_.named_steps['model'], 'coef_'):\n",
    "            print(\"Coefficients:\")\n",
    "            print(grid_search.best_estimator_.named_steps['model'].coef_)\n",
    "\n",
    "    if 'RandomForestRegressor' in model_name:\n",
    "        if hasattr(grid_search.best_estimator_.named_steps['model'], 'feature_importances_'):\n",
    "            print(\"Feature Importance:\")\n",
    "            print(grid_search.best_estimator_.named_steps['model'].feature_importances_)\n",
    "\n",
    "    return mse, r_squared, grid_search.best_params_, training_time\n",
    "\n",
    "# Créer une liste d'algorithmes à tester\n",
    "models_to_test = [\n",
    "    LinearRegression(),\n",
    "    ElasticNet(alpha=0.5, l1_ratio=0.5),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    SVR()\n",
    "]\n",
    "\n",
    "# Définis les grilles de recherche pour chaque modèle\n",
    "param_grids = [\n",
    "    # Grille de recherche pour LinearRegression (aucun hyperparamètre à régler)\n",
    "    {},\n",
    "    \n",
    "    # Grille de recherche pour ElasticNet\n",
    "    {\n",
    "        'model__alpha': [0.001, 0.01, 0.1], \n",
    "        'model__l1_ratio': [0.1, 0.5, 0.9],\n",
    "        'model__max_iter': [1000, 2000]\n",
    "    },\n",
    "    \n",
    "    # Grille de recherche pour RandomForestRegressor\n",
    "    {\n",
    "        'model__n_estimators': [50, 100],\n",
    "        'model__max_depth': [None, 10, 20, 30]\n",
    "    },\n",
    "    \n",
    "    # Grille de recherche pour GradientBoostingRegressor\n",
    "    {\n",
    "        'model__n_estimators': [50, 100],\n",
    "        'model__max_depth': [3, 4, 5]\n",
    "    },\n",
    "    \n",
    "    # Grille de recherche pour SVR\n",
    "    {\n",
    "        'model__C': [0.1, 1],\n",
    "        'model__kernel': ['linear', 'rbf']\n",
    "    }\n",
    "]\n",
    "\n",
    "# Boucle à travers les modèles, effectue la recherche par grille et mesurez le temps de calcul\n",
    "for model, param_grid in zip(models_to_test, param_grids):\n",
    "    mse, r_squared, best_params, training_time = train_evaluate_model_with_grid_search(model, param_grid, X_train, y_train, X_test, y_test)\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    print(\"R²:\", r_squared)\n",
    "    print(\"Training Time\", training_time)\n",
    "    \n",
    "\n",
    "    print()\n",
    "    print(\"************************************************\")\n",
    "    print(\"************************************************\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grid_search.cv_results_` sont les détails de la validation croisée effectuée par GridSearchCV pour évaluer la performance des modèles avec différentes combinaisons d'hyperparamètres. Voici comment interpréter les principales parties de ces résultats :\n",
    "\n",
    "1. **`mean_fit_time` et `std_fit_time`** : Ces deux attributs indiquent le temps moyen (en secondes) que chaque ajustement de modèle a pris pour chaque combinaison d'hyperparamètres, ainsi que l'écart type de ces temps. Cela donne une idée de la durée d'entraînement de chaque modèle.\n",
    "\n",
    "2. **`mean_score_time` et `std_score_time`** : Ils sont similaires à `mean_fit_time` et `std_fit_time`, mais ils mesurent le temps moyen (en secondes) nécessaire pour calculer le score sur les données de validation lors de la validation croisée.\n",
    "\n",
    "3. **`param_...`** : Ces attributs montrent les valeurs des hyperparamètres pour chaque combinaison de paramètres testée. Par exemple, `param_model__alpha` montre les valeurs testées pour l'hyperparamètre `alpha` du modèle ElasticNet.\n",
    "\n",
    "4. **`params`** : Cet attribut est une liste de dictionnaires, chaque dictionnaire contenant les valeurs des hyperparamètres pour une combinaison spécifique.\n",
    "\n",
    "5. **`split0_test_score`, `split1_test_score`, etc.** : Ce sont les scores de validation croisée pour chaque échantillon d'entraînement. Par exemple, `split0_test_score` représente le score pour le premier pli de la validation croisée, `split1_test_score` pour le deuxième pli, etc.\n",
    "\n",
    "6. **`mean_test_score` et `std_test_score`** : Ces attributs fournissent la moyenne et l'écart type des scores de validation croisée sur tous les plis. `mean_test_score` est généralement utilisé pour comparer les performances des modèles avec différentes combinaisons d'hyperparamètres. Une valeur plus élevée est meilleure, car elle indique une meilleure performance.\n",
    "\n",
    "7. **`rank_test_score`** : Cet attribut classe les différentes combinaisons d'hyperparamètres en fonction de leurs performances moyennes (`mean_test_score`). Le modèle avec le meilleur score aura un classement de 1, le deuxième meilleur aura un classement de 2, et ainsi de suite.\n",
    "\n",
    "En général, lorsque vous utilisez `GridSearchCV`, vous recherchez les combinaisons d'hyperparamètres avec les scores `mean_test_score` les plus élevés, car cela indique les meilleures performances de modèle sur les données de validation croisée.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "# Créer un modèle de régression linéaire\n",
    "model = LinearRegression()\n",
    "# Définir les paramètres à tester\n",
    "params = {'normalize': [True, False], 'fit_intercept': [True, False]}\n",
    "# Définir les métriques de scoring à utiliser\n",
    "scoring = {'r2': 'r2', 'mae': 'neg_mean_absolute_error'}\n",
    "# Créer un objet GridSearchCV\n",
    "grid_search = GridSearchCV(model, params, cv=5, scoring=scoring, refit='r2', return_train_score=True)\n",
    "# Exécuter la recherche de grille\n",
    "grid_search.fit(X_train, y_train)\n",
    "# Récupérer les résultats de la validation croisée\n",
    "cv_results = grid_search.cv_results_\n",
    "# Récupérer le meilleur modèle\n",
    "best_model = grid_search.best_estimator_\n",
    "# Faire des prédictions sur l'échantillon test\n",
    "y_pred = best_model.predict(X_test)\n",
    "# Récupérer le MAE et le R2 de l'échantillon test\n",
    "mae = -cv_results['mean_test_mae'][grid_search.best_index_]\n",
    "r2 = cv_results['mean_test_r2'][grid_search.best_index_]\n",
    "# Afficher les résultats\n",
    "print(\"MAE : \", mae)\n",
    "print(\"R2 : \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version avec inclusion Energy Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
